{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d24ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.16\r\n"
     ]
    }
   ],
   "source": [
    "!python --version # should say 3.7.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f80da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agent import Agent, recursive_obs_dict_to_spaces_dict\n",
    "from action_net import ActionNet\n",
    "os.chdir(\"..\")\n",
    "from rice import Rice\n",
    "\n",
    "import torch\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6eb0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Rice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c55c063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 7, 3, 9, 5, 8, 9, 2, 1, 7, 0),\n",
       " tensor([-0.5380, -2.8160, -2.3809, -1.9160, -2.9805, -0.6615, -1.2168, -0.8940,\n",
       "         -1.8528, -2.4258, -2.0461], grad_fn=<CatBackward>))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents[0].act(0, env.reset()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1295e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agents():\n",
    "    initial_observation = env.reset()\n",
    "    agents = []\n",
    "    for key in initial_observation:\n",
    "        agents.append(\n",
    "            Agent(\n",
    "                recursive_obs_dict_to_spaces_dict(initial_observation[0]),\n",
    "                env.action_space[0],\n",
    "                id = key\n",
    "            )\n",
    "        )\n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "087fe5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = create_agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92ff45a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(agents, n_training_episodes, gamma):\n",
    "    \n",
    "    optimizers = {agent.id : torch.optim.Adam(agent.nets[0].parameters(), lr=.0005) for agent in agents}\n",
    "    \n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    \n",
    "    for i_episode in tqdm(range(1, n_training_episodes+1)):\n",
    "        saved_log_probs = {agent.id : [] for agent in agents}\n",
    "        rewards = {agent.id : [] for agent in agents}\n",
    "        state = env.reset()\n",
    "        \n",
    "        # Generate a whole episode\n",
    "        for t in range(env.episode_length):\n",
    "            \n",
    "            collective_action = {}\n",
    "            \n",
    "            for agent in agents:\n",
    "                action, log_prob = agent.act(0, state[agent.id])\n",
    "                saved_log_probs[agent.id].append(log_prob)\n",
    "                collective_action[agent.id] = np.array(action)\n",
    "                \n",
    "            state, reward, done, _ = env.step(collective_action)\n",
    "            \n",
    "            for agent in agents:\n",
    "                rewards[agent.id].append(reward[agent.id])\n",
    "        \n",
    "        returns = {agent.id : deque(maxlen=env.episode_length) for agent in agents} \n",
    "        \n",
    "        # Calculate discounted returns\n",
    "        for t in range(env.episode_length)[::-1]:\n",
    "            for agent in agents:\n",
    "                disc_return_t = (returns[agent.id][0] if len(returns[agent.id])>0 else 0)\n",
    "                returns[agent.id].appendleft( gamma*disc_return_t + rewards[agent.id][t]   )    \n",
    "            \n",
    "        eps = np.finfo(np.float32).eps.item()\n",
    "        \n",
    "        # Standardize returns\n",
    "        returns = {agent.id : torch.tensor(returns[agent.id]) for agent in agents}\n",
    "        for agent in agents:\n",
    "            returns[agent.id] = (returns[agent.id] - returns[agent.id].mean()) / (returns[agent.id].std() + eps)\n",
    "        \n",
    "        # Calculate loss and update weights\n",
    "        policy_loss = {agent.id : [] for agent in agents}\n",
    "        for agent in agents:\n",
    "            for log_prob, disc_return in zip(saved_log_probs[agent.id], returns[agent.id]):\n",
    "                policy_loss[agent.id].append(-log_prob * disc_return)\n",
    "            loss = torch.cat(policy_loss[agent.id]).sum()\n",
    "            \n",
    "            optimizers[agent.id].zero_grad()\n",
    "            loss.backward()\n",
    "            optimizers[agent.id].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7e8fce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:30<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "reinforce(agents, n_training_episodes = 100, gamma = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c70e360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agents(agents):\n",
    "    state = env.reset()\n",
    "    for i in range(env.episode_length):\n",
    "        collective_action = {}\n",
    "    \n",
    "        for agent in agents:\n",
    "            action, _ = agent.act(0, state[agent.id])\n",
    "            collective_action[agent.id] = np.array(action)\n",
    "                \n",
    "        state, reward, done, _ = env.step(collective_action)\n",
    "    return env.global_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7d13b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline():\n",
    "    return evaluate_agents(create_agents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15180fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': array([[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.05850608, 0.72980726, 0.27089572, 0.05207098],\n",
       "        [0.05331389, 0.6906957 , 0.30329227, 0.06162233],\n",
       "        [0.05917268, 0.692366  , 0.39722022, 0.08164351],\n",
       "        [0.05662945, 0.8340226 , 0.28000402, 0.0656942 ],\n",
       "        [0.05810888, 0.8365032 , 0.3569158 , 0.06932385],\n",
       "        [0.06290881, 0.67058283, 0.44530904, 0.08765482],\n",
       "        [0.05929073, 0.7847819 , 0.45354325, 0.085191  ],\n",
       "        [0.05993723, 0.6306677 , 0.41380388, 0.07190837],\n",
       "        [0.06280081, 0.8712302 , 0.4101105 , 0.0798427 ],\n",
       "        [0.06518678, 0.80571026, 0.41909185, 0.09194484],\n",
       "        [0.06158277, 0.8905454 , 0.40946323, 0.08501077],\n",
       "        [0.06207387, 0.8796677 , 0.41144574, 0.08396596],\n",
       "        [0.0669051 , 0.82355547, 0.41746083, 0.08134782],\n",
       "        [0.06300753, 0.73157513, 0.4340559 , 0.08584155],\n",
       "        [0.06654098, 0.8901327 , 0.39776883, 0.08433434],\n",
       "        [0.06389566, 0.8599195 , 0.3237495 , 0.08570278],\n",
       "        [0.06926211, 0.8855331 , 0.51466537, 0.08228391],\n",
       "        [0.06475002, 0.8493277 , 0.47665226, 0.08530188],\n",
       "        [0.06516627, 0.9139504 , 0.5258445 , 0.08875317],\n",
       "        [0.06557599, 0.88705087, 0.5116685 , 0.08867975]], dtype=float32),\n",
       " 'norm': 1.0}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_agents(agents)[\"reward_all_regions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "46b1a696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 4.09122370e-02,  6.24348581e-01,  5.51530644e-02,\n",
       "          4.87187319e-03],\n",
       "        [ 5.10071702e-02,  7.70902336e-01,  2.74724722e-01,\n",
       "          8.67050067e-02],\n",
       "        [ 4.52505685e-02,  7.77053893e-01,  3.52690101e-01,\n",
       "          6.11822903e-02],\n",
       "        [ 1.15539385e-02,  7.11685836e-01, -0.00000000e+00,\n",
       "          6.71878085e-02],\n",
       "        [ 6.78033829e-02,  6.76693901e-08,  4.69006866e-01,\n",
       "          5.21093234e-02],\n",
       "        [ 2.24424917e-02,  8.25839460e-01,  4.58496183e-01,\n",
       "          3.26789566e-03],\n",
       "        [ 6.15346693e-02,  7.92625546e-01,  3.63857120e-01,\n",
       "          9.51857343e-02],\n",
       "        [ 2.65941829e-08,  8.75564933e-01,  5.12179971e-01,\n",
       "          6.24971837e-02],\n",
       "        [ 5.47525883e-02,  6.29430473e-01,  1.33975863e-01,\n",
       "          6.51712045e-02],\n",
       "        [ 3.38395163e-02,  8.71820867e-01,  5.00552118e-01,\n",
       "          2.29037385e-02],\n",
       "        [ 6.65325522e-02,  8.62298906e-01,  4.39100534e-01,\n",
       "          8.89217202e-03],\n",
       "        [ 1.20097380e-02,  6.20844364e-01,  1.57470211e-01,\n",
       "          9.33123007e-02],\n",
       "        [ 6.89106584e-02,  7.50869095e-01, -0.00000000e+00,\n",
       "          6.64691953e-03],\n",
       "        [-0.00000000e+00,  6.67967021e-01,  5.62225044e-01,\n",
       "          5.72581775e-02],\n",
       "        [ 7.05152303e-02,  5.37504792e-01,  2.18133569e-01,\n",
       "          6.31148741e-02],\n",
       "        [ 2.85200047e-04,  9.54105258e-01,  4.04428214e-01,\n",
       "          3.31044607e-02],\n",
       "        [ 5.76201268e-02,  7.92502582e-01,  2.54250288e-01,\n",
       "          8.24919865e-02],\n",
       "        [ 7.05112517e-02,  8.24446559e-01,  5.07252455e-01,\n",
       "          8.89514163e-02],\n",
       "        [ 6.61878213e-02,  8.86691630e-01,  3.16423744e-01,\n",
       "          1.03010423e-01],\n",
       "        [ 3.67264636e-02,  8.58284116e-01,  6.13251567e-01,\n",
       "          6.48259744e-02]], dtype=float32),\n",
       " 'norm': 1.0}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline()[\"reward_all_regions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f784b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
